# ğŸ§  LEXA 
### Your Local AI Pair Programmer & Debugging Assistant  

ğŸš€ **LEXA** is a Streamlit-based coding companion powered by **Ollama** and **LangChain**.  
It helps you write, debug, and understand code â€” all locally, with **zero cloud dependencies**.  

---

## âš™ï¸ Features  

- ğŸ **Expert in Python** (supports multi-language discussions)  
- ğŸ **Smart debugging assistance** with clear reasoning  
- ğŸ§© **Context-aware chat memory**  
- ğŸ§  **Built on DeepSeek (R1 models)** via Ollama  
- ğŸ’¬ **Clean, chat interface**  

---

## ğŸ—ï¸ Tech Stack  

<p align="center">
  <img src="assets/DeepSeek.png" width="80" alt="DeepSeek" width="80" alt="DeepSeek"/>
  <img src="assets/LanChain.png" width="80" alt="LangChain" width="80" alt="LangChain"/>
  <img src="assets/Steamlit" width="80" alt="Streamlit"width="80" alt="Streamlit"/>
  <img src="assets/Ollama.png" width="80" alt="Ollama" width="80" alt="Ollama"/>
</p>

| Component | Description |
|------------|-------------|
| **Streamlit** | UI Framework |
| **LangChain** | Conversational pipeline |
| **Ollama** | Local LLM backend |
| **DeepSeek R1 (1.5B / 3B)** | Model choices |



---

## ğŸ“¦ Installation  

### 1ï¸âƒ£ Install Ollama  
Download Ollama from ğŸ‘‰ [https://ollama.ai/download](https://ollama.ai/download)

### 2ï¸âƒ£ Pull the DeepSeek models  
```bash
ollama pull deepseek-r1:1.5b
ollama pull deepseek-r1:3b
```

### 3ï¸âƒ£ Clone this Repository  

```bash
git clone https://github.com/your-username/codeforge-ai.git
cd codeforge-ai
```

### 4ï¸âƒ£ Install Dependencies  

```bash
pip install streamlit langchain langchain-ollama
```

### ğŸš€ Run the App

Make sure Ollama is running, then start Streamlit:

```bash
streamlit run app.py
```

### ğŸ§© Usage  

- Choose a model (`deepseek-r1:1.5b` or `deepseek-r1:3b`)  
- Type your coding question or paste your code  
- Get instant debugging help, explanations, or refactoring suggestions  

---

## ğŸŒ‘ Example Use Cases  

- Debugging Python scripts  
- Writing documentation  
- Getting algorithm explanations  
- Generating boilerplate code  
- Learning programming interactively  

---

## ğŸ§  Architecture Overview  

```text
User Query 
   â†“
LangChain Prompt Pipeline 
   â†“
DeepSeek via Ollama 
   â†“
AI Response 
   â†“
Streamlit UI
```
## ğŸ› ï¸ Folder Structure  

```text
codeforge-ai/
â”‚
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md              # Project info
```

## USER INTERFACE

![App Screenshot](assets/UI1.png)

![App Screenshot](assets/UI.png)

## ğŸ”’ Data Privacy

One of the key benefits of using **DeepSeek with Ollama** is that all AI processing happens **locally on your device** â€” not in the cloud.  
This means:

- The model runs directly on your machine through Ollama.  
- Your prompts, code, and responses **never leave your computer**.  
- No external APIs or servers are used unless you explicitly connect them.  

In short, **your data stays private and secure**, making this app ideal for developers who value privacy while leveraging AI.


## FURTHER 
we can add the capaility to upload images, audios etc so that they stay on edge and your data satys private.